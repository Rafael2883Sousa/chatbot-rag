# üß† Chatbot RAG sobre Phishing em Ciberseguran√ßa

Este projeto implementa um chatbot baseado em **RAG (Retrieval-Augmented Generation)** utilizando um modelo LLM local (**LLaMA 2**) via `llama.cpp`, com interface web em Flask. O sistema responde exclusivamente com base em documentos sobre **phishing**, sem qualquer fallback gen√©rico do modelo.

---

# RAG (Retrieval-Augmented Generation)

RAG √© uma t√©cnica que combina gera√ß√£o de texto com recupera√ß√£o de informa√ß√£o. Em vez de depender apenas da mem√≥ria do modelo, ele busca informa√ß√µes em documentos externos relevantes para responder uma pergunta. O pipeline b√°sico √©:
‚Ä¢	Consulta ‚Üí Recupera√ß√£o de documentos relevantes ‚Üí Gera√ß√£o com base nos documentos.

---


# Tema: Phishing em ciberseguran√ßa

A escolha do tema Phishing em Ciberseguran√ßa justifica-se pela sua elevada relev√¢ncia pr√°tica, uma vez que o phishing continua a ser uma das amea√ßas mais recorrentes no cen√°rio de seguran√ßa digital. Trata-se de um dom√≠nio rico em conte√∫do informativo, como artigos t√©cnicos, relat√≥rios de incidentes, manuais de preven√ß√£o e diretrizes institucionais. A t√©cnica de RAG (Retrieval-Augmented Generation) encaixa-se perfeitamente nesse contexto, pois permite que o chatbot gere respostas fundamentadas exclusivamente em documentos atualizados ‚Äî como relat√≥rios de amea√ßas recentes ou orienta√ß√µes oficiais ‚Äî, dispensando o re-treinamento do modelo sempre que novas informa√ß√µes s√£o integradas.

Entre os exemplos de aplica√ß√£o deste chatbot, destacam-se perguntas como:
‚Ä¢	‚ÄúComo identificar um e-mail de phishing?‚Äù
‚Ä¢	‚ÄúQual √© a diferen√ßa entre spear phishing e whaling?‚Äù
‚Ä¢	‚ÄúComo configurar SPF e DKIM para mitigar phishing?‚Äù
‚Ä¢	‚ÄúCasos de phishing em Portugal nos √∫ltimos anos?‚Äù
Esses casos demonstram o valor da abordagem RAG na resposta precisa e confi√°vel sobre t√≥picos cr√≠ticos da ciberseguran√ßa.

---

## üéØ Objetivo

Construir um sistema funcional, leve e privado para responder a perguntas sobre phishing em ciberseguran√ßa, usando documentos reais e tecnologia RAG, ideal para projetos acad√™micos ou prot√≥tipos em ambientes controlados.

---

## ‚öôÔ∏è Tecnologias Utilizadas

- `LangChain`
- `llama.cpp` (bin√°rio Windows)
- `Flask` (interface web)
- `FAISS` (armazenamento vetorial local)
- `HuggingFaceEmbeddings` (MiniLM)

---

## üóÇÔ∏è Estrutura do Projeto

```plaintext
chatbot-rag/
‚îú‚îÄ‚îÄ app/                  # Interface web Flask
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ data/                 # Arquivos .txt sobre phishing
‚îú‚îÄ‚îÄ models/               # Modelo LLaMA .gguf
‚îú‚îÄ‚îÄ scripts/              # Scripts auxiliares (chunks, vetores, chatbot)
‚îÇ   ‚îú‚îÄ‚îÄ chunk_texts.py
‚îÇ   ‚îú‚îÄ‚îÄ generate_vectorstore.py
‚îÇ   ‚îî‚îÄ‚îÄ chatbot.py
‚îú‚îÄ‚îÄ vectorstore/          # Armazenamento FAISS
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Instala√ß√£o

1. **Pr√©-requisitos**:
   - Windows 10
   - Python 3.10+
   - `llama.cpp` bin√°rio (ex: `llama-b5760-bin-win-cpu-x64.zip`)

2. **Ambiente virtual**:
   ```cmd
   python -m venv ragenv
   ragenv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Modelo**:
   - Baixe `.gguf` de [TheBloke/Llama-2-7B-Chat-GGUF](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF)
   - Coloque em `models/`

4. **Documentos**:
   - Arquivos `.txt` sobre phishing em `data/`

---

## üß© Execu√ß√£o

### üîπ Gerar Chunks
```cmd
python scripts\chunk_texts.py
```

### üîπ Criar Vetor FAISS
```cmd
python scripts\generate_vectorstore.py
```

### üîπ Testar via Terminal
```cmd
python scripts\chatbot.py
```

### üîπ Interface Web
```cmd
cd app
python app.py
```
Abra `http://127.0.0.1:5000/` no navegador.

---

## üß† Exemplo de Uso

> **Pergunta**: Quais os tipos de phishing mais comuns?  
> **Resposta**: Spear phishing, whaling, vishing e smishing s√£o os principais tipos, cada um explorando diferentes meios e alvos...

---

## üõ°Ô∏è Seguran√ßa

Este projeto **n√£o envia dados para a internet**. Toda a infer√™ncia e recupera√ß√£o s√£o locais. O modelo n√£o gera respostas fora do escopo dos documentos.

---

## ‚ö†Ô∏è Limita√ß√µes

- Pode n√£o responder se os documentos n√£o contiverem a resposta.
- Utiliza apenas 3 chunks mais relevantes.
- Modelo LLaMA roda com desempenho limitado em CPUs mais antigos.
